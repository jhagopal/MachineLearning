{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0kOE0q97weKU2pPFk3zAp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhagopal/MachineLearning/blob/main/dragonfruitai_submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import os\n",
        "\n",
        "Image.MAX_IMAGE_PIXELS = None"
      ],
      "metadata": {
        "id": "3YpkEwx2aC7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Generation"
      ],
      "metadata": {
        "id": "Io47WY90bg1W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAsEx0R0Z_kz"
      },
      "outputs": [],
      "source": [
        "# Define the new image dimensions\n",
        "new_width = 100000\n",
        "new_height = 100000\n",
        "\n",
        "# Create an empty NumPy array of zeros with the new specified dimensions\n",
        "new_image_array = np.zeros((new_height, new_width), dtype=np.uint8)\n",
        "\n",
        "# Set the top-left quadrant to 1\n",
        "new_image_array[:new_height // 2, :new_width // 2] = 1\n",
        "\n",
        "# Enable compression and save the new image with compression\n",
        "compression_method = \"tiff_lzw\"  # You can choose the compression method you prefer\n",
        "with tqdm(total=3, desc=\"Processing images\") as pbar:\n",
        "    new_image_pil = Image.fromarray(new_image_array)\n",
        "    new_image_pil.save(\"modified_mo1.tiff\", compression=compression_method)\n",
        "    pbar.update(1)\n",
        "\n",
        "    # Set the center pixel to 1 in the image (modified_dye1.tiff)\n",
        "    new_image_array[new_height // 2, new_width // 2] = 1\n",
        "    new_image_pil = Image.fromarray(new_image_array)\n",
        "    new_image_pil.save(\"modified_dye1.tiff\", compression=compression_method)\n",
        "    pbar.update(1)\n",
        "\n",
        "    # Reset new image to all zeros\n",
        "    new_image_array = np.zeros((new_height, new_width), dtype=np.uint8)\n",
        "    # Save an empty new image (modified_dye2.tiff)\n",
        "    new_image_pil = Image.fromarray(new_image_array)\n",
        "    new_image_pil.save(\"modified_dye2.tiff\", compression=compression_method)\n",
        "    pbar.update(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_img(img_path):\n",
        "    img = Image.open(img_path)\n",
        "    img_array = np.array(img)\n",
        "    return img_array\n",
        "\n",
        "\n",
        "modified_mo1_array = encode_img('modified_mo1.tiff')\n",
        "modified_dye1_array = encode_img('modified_dye1.tiff')\n",
        "modified_dye2_array = np.zeros((new_height, new_width), dtype=np.uint8)"
      ],
      "metadata": {
        "id": "2T3vrCs8aGhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rle_encode(img_array):\n",
        "    rows, cols = img_array.shape\n",
        "    rle_data = []\n",
        "\n",
        "    prev_value = img_array[0, 0]\n",
        "    count = 1\n",
        "\n",
        "    # Add tqdm around the outer loop (rows) for progress tracking\n",
        "    for r in tqdm(range(rows), desc=\"Encoding\"):\n",
        "        for c in range(cols):\n",
        "            if (r == 0 and c == 0):  # Skip the first pixel since we already initialized it\n",
        "                continue\n",
        "\n",
        "            current_value = img_array[r, c]\n",
        "\n",
        "            if current_value == prev_value:\n",
        "                count += 1\n",
        "            else:\n",
        "                rle_data.extend([prev_value, count])\n",
        "                prev_value = current_value\n",
        "                count = 1\n",
        "\n",
        "    rle_data.extend([prev_value, count])  # Add the last run\n",
        "    return rle_data\n",
        "\n",
        "\n",
        "modified_mo1_rle = rle_encode(modified_mo1_array)"
      ],
      "metadata": {
        "id": "50rlN233aKuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rle_decode(rle_data, shape):\n",
        "    \"\"\"Decodes an RLE encoded array to its original form.\"\"\"\n",
        "    array = np.zeros(shape, dtype=np.uint8)\n",
        "    position = 0\n",
        "\n",
        "    for i in range(0, len(rle_data), 2):\n",
        "        value = rle_data[i]\n",
        "        count = rle_data[i + 1]\n",
        "\n",
        "        # Mark the positions with the given value\n",
        "        array.flat[position:position + count] = value\n",
        "        position += count\n",
        "\n",
        "    return array"
      ],
      "metadata": {
        "id": "ieplQyJfaXYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def has_cancer_rle(rle_encoded_array1, array2):\n",
        "    start_time = time.time()\n",
        "\n",
        "    common_ones = 0\n",
        "    total_ones_in_array1 = 0\n",
        "    position = 0\n",
        "\n",
        "    for i in range(0, len(rle_encoded_array1), 2):\n",
        "        value = rle_encoded_array1[i]\n",
        "        count = rle_encoded_array1[i + 1]\n",
        "\n",
        "        if value == 1:\n",
        "            total_ones_in_array1 += count\n",
        "            common_ones += np.count_nonzero(array2[position:position + count])\n",
        "\n",
        "        position += count\n",
        "\n",
        "    # Calculate the ratio\n",
        "    if total_ones_in_array1 == 0:\n",
        "        ratio = 0\n",
        "    else:\n",
        "        ratio = common_ones / total_ones_in_array1\n",
        "\n",
        "    # Check if the ratio is greater than 0.1\n",
        "    result = ratio > 0.1\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    # Print the execution time\n",
        "    print(f\"Execution time: {elapsed_time} seconds\")\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "1Uz6jEQeaYu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_data = {}\n",
        "import os\n",
        "\n",
        "def process_images(microscope_image, dye_image):\n",
        "    # Extract the base filename without the extension\n",
        "    key = os.path.splitext(os.path.basename(microscope_image))[0]\n",
        "\n",
        "    # Convert microscope_image and dye_image to NumPy arrays\n",
        "    microscope_array = encode_img(microscope_image)\n",
        "    microscope_rle = rle_encode(microscope_array)\n",
        "    dye_array = encode_img(dye_image)\n",
        "\n",
        "    # Check if the images have cancer using has_cancer_optimized function\n",
        "    if has_cancer_rle(microscope_rle, dye_array):\n",
        "        # If True, store both images in the dictionary\n",
        "        image_data[key] = [microscope_rle, dye_array]\n",
        "    else:\n",
        "        # If False, store only the microscope image\n",
        "        image_data[key] = [microscope_rle, None]"
      ],
      "metadata": {
        "id": "2rJi7WaVaeQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_rle_as_tiff(rle_data, shape, filename, compression=\"tiff_lzw\"):\n",
        "    # Decode the RLE data\n",
        "    img_array = rle_decode(rle_data, shape)\n",
        "    # Convert to PIL Image\n",
        "    img_pil = Image.fromarray(img_array)\n",
        "    # Save as .tiff\n",
        "    img_pil.save(filename, compression=compression)"
      ],
      "metadata": {
        "id": "woVBamEAagOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer 1"
      ],
      "metadata": {
        "id": "AH0H6FLGctyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For representing images generated by the microscope, the RLE (Run Length Encoding) format is a suitable choice. This format efficiently stores consecutive runs of pixels with the same value, which is beneficial for images with large contiguous regions of the same color. In the worst-case scenario, where the image alternates between black (0) and white (1) for every pixel, the storage size for RLE encoding would be\n",
        "8\n",
        "√ó\n",
        "ùëÅ\n",
        "√ó\n",
        "ùëÄ\n",
        "8√óN√óM bytes, which is 80GB for a 100,000x100,000 image. However, in practice, such extreme cases are rare, and RLE encoding would offer significant storage savings for images with large continuous regions of the same color.\n",
        "\n",
        "For representing images generated by the dye sensor, storing them as dense matrices (2D arrays) is a suitable choice. Each pixel in the image is represented by a single byte (uint8), resulting in a storage size of\n",
        "ùëÅ\n",
        "√ó\n",
        "ùëÄ\n",
        "N√óM bytes, which is 10GB for a 100,000x100,000 image. Dense matrices are straightforward to work with and provide constant-time access to individual pixel values, making them suitable for storing images with varying dye concentrations across the entire image."
      ],
      "metadata": {
        "id": "m-3lAcOLc0c2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer 2"
      ],
      "metadata": {
        "id": "fyVhzsacdT2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the microscope image (mo1), you simulate a simple scenario where the top-left quadrant is completely black, representing the parasite, while the rest of the image is white. This scenario is realistic and provides a straightforward test case for your RLE encoding.\n",
        "\n",
        "For the dye sensor images (dye1 and dye2), you simulate scenarios where the top-left quadrant is black, similar to the microscope image, and an additional blob (adjacent pixel) is added to simulate dye leakage. This helps in testing the functionality of your algorithm to detect dye presence both within and outside the parasite area.\n",
        "\n",
        "Encoding the microscope image (mo1) using RLE encoding and dye sensor images (dye1 and dye2) into dense NumPy matrices provides a realistic simulation of the data that would be captured by the microscope and dye sensor. This approach allows you to test your code under realistic conditions before working with real images."
      ],
      "metadata": {
        "id": "UOfPYZOndX0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer 3"
      ],
      "metadata": {
        "id": "0rXUZgcddkNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previous approach:\n",
        "\n",
        "It calculates the ratio of common non-zero values (representing dye within the parasite) to the total non-zero values in the microscope image. This ratio indicates the proportion of the parasite area that contains dye.\n",
        "Check Threshold:\n",
        "It checks if the calculated ratio exceeds the threshold of 0.1, indicating that the total amount of dye detected within the parasite area exceeds 10% of the total parasite area.\n",
        "Determine Cancer:\n",
        "If the ratio is greater than 0.1, the function concludes that the parasite has cancer and returns True. Otherwise, it returns False, indicating that the parasite does not have cancer."
      ],
      "metadata": {
        "id": "fjeAXbSNdmWg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer 4"
      ],
      "metadata": {
        "id": "U9AGW_T3eSXf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function efficiently computes whether a parasite has cancer based on the RLE encoded representation of the microscope image and the dense matrix representation of the dye sensor image, providing insights into the presence of cancerous tissue within the parasite.\n",
        "\n",
        "For each run in the RLE encoded array, if the value is 1 (black pixel representing the parasite), the count of black pixels within that run is calculated using NumPy's count_nonzero function on the corresponding section of the dense matrix representation of the dye sensor image. The total number of black pixels within the microscope image is also accumulated. After processing all runs, the function calculates the ratio of black pixels within the parasite area to the total area occupied by the parasite in the microscope image. If the ratio is greater than 0.1 (indicating that the total amount of dye detected in the parasite's body exceeds 10% of the area occupied by the parasite), the function returns True, indicating that the parasite has cancer. Otherwise, it returns False."
      ],
      "metadata": {
        "id": "jyW9P7fIeUjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer 5"
      ],
      "metadata": {
        "id": "WRe0xGU6fDED"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downsampling:\n",
        "Downsampling involves reducing the resolution of the image by averaging or subsampling pixels. This can significantly reduce the storage size of the image but may result in loss of detail.\n",
        "Downsampling a 100,000x100,000 image to 10x10 would reduce the storage size by a factor of 10,000. However, this reduction in resolution may impact the accuracy of cancer detection, especially for detecting small parasites or subtle variations in dye concentration.\n",
        "Runtime impact: Downsampling typically involves iterating through the image pixels and performing averaging or subsampling operations, which can be computationally expensive for large images."
      ],
      "metadata": {
        "id": "xIJ0lv2tfFKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer 6"
      ],
      "metadata": {
        "id": "Wy_tS8KHfcM1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Here are the tools and resources used for this assignment:\n",
        "\n",
        "GitHub: Used for version control and reference codes. Storing code snippets, scripts, and project files for collaboration and sharing.\n",
        "Google: Utilized for research about handling large images, compression techniques, and optimization strategies. Gathering information, tutorials, and documentation related to image processing.\n",
        "ChatGPT: Leveraged for code assistance, debugging, and brainstorming ideas. Utilizing the AI model to generate code snippets, explain concepts, and provide guidance on various aspects of the assignment\n",
        "Python: Specifically, libraries such as tifffile and PIL (Python Imaging Library) were used for image processing tasks. tifffile for reading and writing TIFF images, and PIL for various image manipulation operations such as resizing, encoding, and decoding."
      ],
      "metadata": {
        "id": "lAmYhlJ5ftHp"
      }
    }
  ]
}